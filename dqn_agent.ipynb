{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n",
      "episode:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thebird/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/thebird/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/thebird/anaconda3/lib/python3.7/site-packages/paho/mqtt/client.py\", line 3452, in _thread_main\n",
      "    self.loop_forever(retry_first_connection=True)\n",
      "  File \"/Users/thebird/anaconda3/lib/python3.7/site-packages/paho/mqtt/client.py\", line 1779, in loop_forever\n",
      "    rc = self.loop(timeout, max_packets)\n",
      "  File \"/Users/thebird/anaconda3/lib/python3.7/site-packages/paho/mqtt/client.py\", line 1181, in loop\n",
      "    rc = self.loop_read(max_packets)\n",
      "  File \"/Users/thebird/anaconda3/lib/python3.7/site-packages/paho/mqtt/client.py\", line 1572, in loop_read\n",
      "    rc = self._packet_read()\n",
      "  File \"/Users/thebird/anaconda3/lib/python3.7/site-packages/paho/mqtt/client.py\", line 2310, in _packet_read\n",
      "    rc = self._packet_handle()\n",
      "  File \"/Users/thebird/anaconda3/lib/python3.7/site-packages/paho/mqtt/client.py\", line 2936, in _packet_handle\n",
      "    return self._handle_publish()\n",
      "  File \"/Users/thebird/anaconda3/lib/python3.7/site-packages/paho/mqtt/client.py\", line 3216, in _handle_publish\n",
      "    self._handle_on_message(message)\n",
      "  File \"/Users/thebird/anaconda3/lib/python3.7/site-packages/paho/mqtt/client.py\", line 3444, in _handle_on_message\n",
      "    self.on_message(self, self._userdata, message)\n",
      "  File \"/Users/thebird/Desktop/Code/JupyterNB/Sumobot/sumobot_real.py\", line 20, in on_message\n",
      "    state[i] = int(arr[i])\n",
      "ValueError: invalid literal for int() with base 10: '[-54'\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'angle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4c9743b96cc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# https://www.freecodecamp.org/news/if-name-main-python-example/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;31m#     print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4c9743b96cc0>\u001b[0m in \u001b[0;36mtrain_dqn\u001b[0;34m(episode)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m#             enemy_action = enemy_agent.act(enemy_state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;31m#             enemy_reward, enemy_next_state, enemy_done = env.step_enemy(enemy_action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Code/JupyterNB/Sumobot/sumobot_real.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0;31m#enemy below the robot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0;31m#enemy on top of the robot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'angle' is not defined"
     ]
    }
   ],
   "source": [
    "from sumobot_real import Sumobot\n",
    "\n",
    "import random, sys\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "env = Sumobot()\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "class DQN:\n",
    "\n",
    "    \"\"\" Implementation of deep q learning algorithm \"\"\"\n",
    "\n",
    "    def __init__(self, action_space, state_space): #making the agent\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.epsilon = 1\n",
    "        self.gamma = .95\n",
    "        self.batch_size = 64\n",
    "        self.epsilon_min = .01\n",
    "        self.epsilon_decay = .995\n",
    "        self.learning_rate = 0.001\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.model = self.build_model()\n",
    "        self.episode_coords = [0,0] # will be a 2x2 matrix\n",
    "        self.angle = 0\n",
    "        self.radius = 44\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        model = Sequential() #groups a linear stack of layers into a model, provides training and inference features on this model\n",
    "        model.add(Dense(64, input_shape=(self.state_space,), activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(self.action_space, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_space) #choose a random move\n",
    "        act_values = self.model.predict(state) # Generates output predictions for the input samples.\n",
    "        return np.argmax(act_values[0]) \n",
    "\n",
    "    def replay(self):\n",
    "    \n",
    "#         print(len(self.memory))\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        states = np.array([i[0] for i in minibatch])\n",
    "        actions = np.array([i[1] for i in minibatch])\n",
    "        rewards = np.array([i[2] for i in minibatch])\n",
    "        next_states = np.array([i[3] for i in minibatch])\n",
    "        dones = np.array([i[4] for i in minibatch])\n",
    "\n",
    "        states = np.squeeze(states)\n",
    "        next_states = np.squeeze(next_states)\n",
    "\n",
    "        targets = rewards + self.gamma*(np.amax(self.model.predict_on_batch(next_states), axis=1))*(1-dones)\n",
    "        targets_full = self.model.predict_on_batch(states)\n",
    "\n",
    "        ind = np.array([i for i in range(self.batch_size)])\n",
    "        targets_full[[ind], [actions]] = targets\n",
    "\n",
    "        self.model.fit(states, targets_full, epochs=1, verbose = 0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "    def sumobot_spiral(self, angle, radius):\n",
    "        x = math.sqrt((radius**2)/(1 + (math.tan(math.radians(angle)))**2))\n",
    "        y = x * math.tan(math.radians(angle))\n",
    "        if 0 <= angle <= 90:\n",
    "            self.episode_coords[0] = [-x,-y]\n",
    "        elif 90 < angle <= 180:\n",
    "            self.episode_coords[0] = [x,y]\n",
    "        elif 180 < angle <= 270:\n",
    "            self.episode_coords[0] = [x,y]\n",
    "        elif 270 < angle < 360:\n",
    "            self.episode_coords[0] = [-x,-y]\n",
    "            \n",
    "    for i in range(3):\n",
    "            self.sumobot.goto(self.radius, 0)\n",
    "            while(self.angle < 360):             \n",
    "                self.sumobot_spiral(self.angle, self.radius)\n",
    "                self.enemy_locs(self.sumobot.xcor(), self.sumobot.ycor())\n",
    "                self.angle += self.angle_delta\n",
    "            self.angle -= 360 \n",
    "            self.radius += 10 \n",
    "\n",
    "        \n",
    "    def enemy_locs(self, xcor, ycor):\n",
    "        enemy_angle = 0\n",
    "        dist = [17, 34, 51]\n",
    "        enemy_angle_delta = 45\n",
    "        ex = 0\n",
    "        ey = 0\n",
    "        for r in dist:  \n",
    "            while(enemy_angle < 360):\n",
    "                if enemy_angle <= 90 or enemy_angle > 270: \n",
    "                    ex = xcor - math.sqrt((r**2)/(1+(math.tan(math.radians(enemy_angle))**2)))\n",
    "                    ey = ycor - (ex - xcor) * math.tan(math.radians(enemy_angle)) \n",
    "                else:\n",
    "                    ex = xcor + math.sqrt((r**2)/(1+(math.tan(math.radians(enemy_angle))**2)))\n",
    "                    ey = ycor + (ex - xcor) * math.tan(math.radians(enemy_angle))  \n",
    "                    \n",
    "                if (math.sqrt(ex**2 + ey**2) < self.arena_radius):\n",
    "                    if 0 <= enemy_angle <= 90:\n",
    "                        if enemy_angle == 90:\n",
    "                            self.episode_coords[1] = [ex,-ey-r]\n",
    "                        else:\n",
    "                            self.episode_coords[1] = [ex,-ey]\n",
    "                    elif 90 < enemy_angle <= 180:\n",
    "                        if enemy_angle == 180:\n",
    "                            self.episode_coords[1] = [ex-r,ey]\n",
    "                        else:\n",
    "                            self.episode_coords[1] = [ex,ey]\n",
    "                    elif 180 < enemy_angle <= 270:\n",
    "                        if enemy_angle == 270:\n",
    "                            if r == 17 :\n",
    "                                self.episode_coords[1] = [ex,ey+r]\n",
    "                            else: \n",
    "                                self.episode_coords[1] = [ex,ey]\n",
    "                        else:\n",
    "                            self.episode_coords[1] = [ex,ey]\n",
    "                    elif 270 < enemy_angle <= 360:\n",
    "                        if enemy_angle == 315:\n",
    "                            if r == 34:\n",
    "                                self.episode_coords[1] = [ex,-ey]\n",
    "                            else:\n",
    "                                self.episode_coords[1] = [ex,-ey]\n",
    "                        else:\n",
    "                            self.episode_coords[1] = [ex,ey]\n",
    "                else: \n",
    "                    pass\n",
    "#                     self.enemy.pd()\n",
    "#                     self.enemy.dot('red')\n",
    "#                     self.enemy.pu()\n",
    "                enemy_angle += enemy_angle_delta\n",
    "#                 time.sleep(0.5)\n",
    "            enemy_angle -= 360\n",
    "            \n",
    "\n",
    "\n",
    "def train_dqn(episode):\n",
    "\n",
    "    loss = []\n",
    "    #sumobot and enemy action and state space\n",
    "    action_space = 9\n",
    "    state_space = 4\n",
    "    max_steps = 20\n",
    "    #sumobot agent\n",
    "    agent = DQN(action_space, state_space)\n",
    "    for e in range(episode):\n",
    "        # the reset here will take the four coordinates where to bot should move to\n",
    "        # the only place where the algorithm resets the sumobot\n",
    "        state = env.reset(self.episode_coords) \n",
    "        state = np.reshape(state, (1, state_space))\n",
    "        score = 0\n",
    "        print(\"episode: \", e)\n",
    "        for i in range(max_steps):\n",
    "            #enemey agent\n",
    "            action = agent.act(state)\n",
    "            reward, next_state, done = env.step(action)\n",
    "            score += reward\n",
    "            next_state = np.reshape(next_state, (1, state_space))\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            agent.replay()\n",
    "            if done:\n",
    "#                 print(\"episode: {}/{}, score: {}\".format(e, episode, score))\n",
    "                agent.model.summary()\n",
    "                break\n",
    "        loss.append(score)\n",
    "    #save both models\n",
    "    agent.model.save('model.h5')\n",
    "    return loss\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "# So when the interpreter runs a module, the __name__ variable will be set as  __main__ if the module that is being run is the main program.\n",
    "# But if the code is importing the module from another module, then the __name__  variable will be set to that module’s name.\n",
    "# https://www.freecodecamp.org/news/if-name-main-python-example/\n",
    "    ep = 100\n",
    "    loss = train_dqn(ep)\n",
    "#     print(loss)\n",
    "    plt.plot([i for i in range(ep)], loss)\n",
    "    plt.xlabel('episodes')\n",
    "    plt.ylabel('reward')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
