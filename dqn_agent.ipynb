{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "episode:  0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 5,065\n",
      "Trainable params: 5,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sumobot import Sumobot\n",
    "import tensorflow as tf\n",
    "import random, sys\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# from tf.keras.layers import Dense\n",
    "# from tf.keras.optimizers import Adam\n",
    "print(tf.__version__)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "env = Sumobot()\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "class DQN:\n",
    "\n",
    "    \"\"\" Implementation of deep q learning algorithm \"\"\"\n",
    "\n",
    "    def __init__(self, action_space, state_space): #making the agent\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.epsilon = 1\n",
    "        self.gamma = .95\n",
    "        self.batch_size = 64\n",
    "        self.epsilon_min = .01\n",
    "        self.epsilon_decay = .995\n",
    "        self.learning_rate = 0.001\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        model = tf.keras.Sequential() #groups a linear stack of layers into a model, provides training and inference features on this model\n",
    "        model.add(tf.keras.layers.Dense(64, input_shape=(self.state_space,), activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(self.action_space, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "#         print(np.random.rand() <= self.epsilon)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_space) #choose a random move\n",
    "        act_values = self.model.predict(state) # Generates output predictions for the input samples.\n",
    "        return np.argmax(act_values[0]) \n",
    "\n",
    "    def replay(self):\n",
    "    \n",
    "#         print(len(self.memory))\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        states = np.array([i[0] for i in minibatch])\n",
    "        actions = np.array([i[1] for i in minibatch])\n",
    "        rewards = np.array([i[2] for i in minibatch])\n",
    "        next_states = np.array([i[3] for i in minibatch])\n",
    "        dones = np.array([i[4] for i in minibatch])\n",
    "\n",
    "        states = np.squeeze(states)\n",
    "        next_states = np.squeeze(next_states)\n",
    "\n",
    "        targets = rewards + self.gamma*(np.amax(self.model.predict_on_batch(next_states), axis=1))*(1-dones)\n",
    "        targets_full = self.model.predict_on_batch(states)\n",
    "\n",
    "        ind = np.array([i for i in range(self.batch_size)])\n",
    "        targets_full[[ind], [actions]] = targets\n",
    "\n",
    "        self.model.fit(states, targets_full, epochs=1, verbose = 0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "\n",
    "\n",
    "def train_dqn(episode):\n",
    "\n",
    "    loss = []\n",
    "#     enemy_loss = []\n",
    "    #sumobot and enemy action and state space\n",
    "    action_space = 9\n",
    "    state_space = 4\n",
    "#     enemy_action_space = 1\n",
    "    max_steps = 2000\n",
    "    #sumobot agent\n",
    "    agent = DQN(action_space, state_space)\n",
    "    #enemy agent\n",
    "#     enemy_agent = DQN(enemy_action_space, state_space)\n",
    "    for e in range(episode):\n",
    "        state = env.reset() # the only place where the algorithm resets the sumobot\n",
    "        state = np.reshape(state, (1, state_space))\n",
    "        #enemy state and reset in py\n",
    "#         enemy_state = env.reset_enemy()\n",
    "#         enemy_state = np.reshape(enemy_state, (1, state_space))\n",
    "        score = 0\n",
    "#         enemy_score = 0\n",
    "        print(\"episode: \", e)\n",
    "        for i in range(max_steps):\n",
    "            #enemey agent\n",
    "            action = agent.act(state)\n",
    "#             enemy_action = enemy_agent.act(enemy_state)\n",
    "            reward, next_state, done = env.step(action)\n",
    "#             enemy_reward, enemy_next_state, enemy_done = env.step_enemy(enemy_action)\n",
    "            score += reward\n",
    "#             enemy_score += enemy_reward\n",
    "            next_state = np.reshape(next_state, (1, state_space))\n",
    "#             enemy_next_state = np.reshape(enemy_next_state, (1, state_space))\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "#             enemy_agent.remember(enemy_state, enemy_action, enemy_reward, enemy_next_state, enemy_done)\n",
    "            state = next_state\n",
    "#             enemy_state = enemy_next_state\n",
    "            agent.replay()\n",
    "#             enemy_agent.replay()\n",
    "            if done:\n",
    "#                 print(\"episode: {}/{}, score: {}\".format(e, episode, score))\n",
    "                agent.model.summary()\n",
    "#                 enemy_agent.model.summary()\n",
    "                break\n",
    "        loss.append(score)\n",
    "#         enemy_loss.append(enemy_score)\n",
    "    #save both models\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(agent.model)\n",
    "    tflite_model = converter.convert()\n",
    "#     tflite_model.save(\"myModelLite1.h5\")\n",
    "    tflite_model_name = \"mymodel.tflite\"\n",
    "    open(tflite_model_name, \"wb\").write(tflite_model)\n",
    "    return loss #, enemy_loss\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "# So when the interpreter runs a module, the __name__ variable will be set as  __main__ if the module that is being run is the main program.\n",
    "# But if the code is importing the module from another module, then the __name__  variable will be set to that moduleâ€™s name.\n",
    "# https://www.freecodecamp.org/news/if-name-main-python-example/\n",
    "    ep = 1\n",
    "    loss = train_dqn(ep)\n",
    "#     print(loss)\n",
    "    plt.plot([i for i in range(ep)], loss)\n",
    "    plt.xlabel('episodes')\n",
    "    plt.ylabel('reward')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
